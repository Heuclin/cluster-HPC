---
output:
  word_document: default
  html_document: default
---




![](Figures/logos.png)

# Introduction au cluster de calcul MESO@LR 


***Axe transversal TIM, UR AIDA***

*Benjamin Heuclin, Ing√©nieur statisticien, UR AIDA, Cirad*

*Septembre 2022*

Licence : <a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/"><img alt="Licence Creative Commons" style="border-width:0" src="https://i.creativecommons.org/l/by-nc/4.0/88x31.png" /></a><br />Ce(tte) ≈ìuvre est mise √† disposition selon les termes de la <a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/">Licence Creative Commons Attribution - Pas d‚ÄôUtilisation Commerciale 4.0 International</a>.




___

1. [C'est quoi un supercalculateur ? et la parall√©lisation ?](#cluster_parallelisation)
    1. [La paral√©lisation](#parallelisation)
    2. [Cluster de calcul MUSE (MESO@LR)](#cluster)
2. [Connexion au Cluster](#connexion)
3. [Transfer de fichier](#transfer) 
4. [Les espaces de stockage](#stockage)
5. [Procedure de soumission de jobs R](#proc_soumission)
6. [Les commandes SLURM utiles](#commandes)
7. [Rstudio sur le cluster](#rstudio) 
8. [Ressources](#ressources)
*  [Annexes](#annexes)

    A.[ Les exemples](#annexes_exemples)
      1. [Exemple R OpenMP sur calibration d'une RF](#ex_R_openMP)
      2. [Exemple R openMP for loop](#ex_R_forloop)
      3. [Exemple R array](#ex_R_array)
      
    B. [Script batch corrompu √† cause des retours √† la ligne WINDOWS](#annexes_unix_LF)
    
    C. [rsync](#annexes_rsunc)
    
    
    
___










> üö® Ce document se limite √† l'utilisation de R sur CPU, avec une parall√©lisation en m√©moire partag√©e (openMP). C'est une initiation pour prendre rapidement en main le processus de soumission de jobs.

Pour les agents Cirad, il faut demander l'acc√®s √† Bertrand Pitollat ([bertrand.pitollat@cirad.fr](mailto:bertrand.pitollat@cirad.fr)) en lui envoyant un email en pr√©cisant l'unit√©, votre num√©ro de poste t√©l√©phonique CIRAD accompagn√© de la charte sign√©e.  


Vous obtenez  ainsi un nom d'utilisateur (g√©n√©ralement celui de votre compte Cirad) et un mot de passe (g√©n√©ralement le m√™me que celui de votre compte Cirad).

Pour utiliser le cluster, il faut un terminal unix pour ce connect, soumettre et g√©rer vos jobs et un logiciel de transfert de fichier pour envoyer vos codes, ... de votre PC vers le cluster et vice-versa.


Documentation Muse : https://meso-lr.umontpellier.fr/documentation-utilisateurs/



[######################################################################################]: # 

<br><br>

# 1. C'est quoi un supercalculateur ? et la parall√©lisation ? {#cluster_parallelisation}

---


[D√©finition wikip√©dia](https://fr.wikipedia.org/wiki/Superordinateur) : <br>
Un superordinateur ou supercalculateur est un ordinateur con√ßu pour atteindre les plus hautes performances possibles avec les techniques connues lors de sa conception, en particulier en ce qui concerne la vitesse de calcul. Pour des raisons de performance, c'est presque toujours un ordinateur central, dont les t√¢ches sont fournies en traitement par lots. <br>
La science des superordinateurs est appel√©e ¬´ calcul haute performance ¬ª (en anglais : high-performance computing ou HPC). 

Un supercalculateur est g√©n√©ralement un regroupement plusieurs ordinateurs ind√©pendants appel√©s n≈ìuds (node en anglais) d'o√π l'app√©lation √©galement sous le terme de cluster de calcul.



## 1.1 La parall√©lisation {#parallelisation}

Ce lien explique tr√®s bien les diff√©rents types de parall√©lisation :

https://cwant.github.io/hpc-beyond/21-introduction-to-parallelism/index.html

> Une t√¢che (ou processus, ou thread) est une unit√© de traitement logique


* **Strat√©gie de m√©moire partag√©e :** il s'agit de la situation o√π votre programme ex√©cute des t√¢ches sur pluisieurs CPUs (1 par t√¢che) sur le m√™me n≈ìud, et chaque CPU peut acc√©der √† toute la m√©moire utilis√©e par le programme. Une biblioth√®que tr√®s largement utilis√©e pour r√©aliser ce type de parall√©lisme est OpenMP (Open Multi-Processing).<br>
Ce type de parall√©lisation peut se produire pendant l'ex√©cution d'une boucle "for" sp√©cifique en r√©partissant la boucle entre les diff√©rents CPUs. <br>
**Ce type de paral√©lisation est r√©alisable sur ton PC.**

* **Strat√©gie de m√©moire distribu√©e :** chaque t√¢che est ex√©cut√© sur un CPU (sur un noeud) qui poss√®de sa propre m√©moire qui lui est priv√©e, et aucune autre CPU ne peut voir cette m√©moire (ind√©pendance). Afin de communiquer ce qui se trouve dans l'espace m√©moire d'un CPU √† un autre, les CPUs se "passent des messages". Gr√¢ce √† cette conception, le code est modularis√© de telle sorte que certaines parties du programme peuvent √™tre ex√©cut√©es sur plusieurs machines diff√©rentes (n≈ìuds), chaque machine devant travailler avec son propre espace m√©moire.
Une biblioth√®que populaire pour impl√©menter ce type de parall√©lisme est appel√©e MPI (Message Passing Interface). <br>


* **Strat√©gie hybride :** la m√©moire est distribu√©e entre les n≈ìuds, mais sur chaque n≈ìud le code peut utiliser une strat√©gie de m√©moire partag√©e. Cela pourrait √™tre un cas o√π vous voulez utiliser MPI pour faire passer des messages entre chaque n≈ìud, mais sur chaque n≈ìud vous utilisez une strat√©gie de m√©moire partag√©e utilisant OpenMP. <br>



![](Figures/parallelisation.png)

**En r√©sum√© :**

|          | 1 node       | n nodes |
| :------- | :----------- | :------ |
| 1 CPU    | Job en s√©rie | MPI     |
| n CPUs   | OpenMP       | hybride : OpenMPI |




<br>

## 1.2 Le cluster de calcul MUSE (MESO@LR) {#cluster}

**Les chiffres :**

* 308 n≈ìuds (nodes) de calcul Dell PowerEdge C6320
    - bi processeurs Intel Xeon E5-2680 v4 2,4 Ghz (broadwell)
    - **28 CPUs par n≈ìuds**, total : 8624 CPUs 
    - 128 Go RAM par n≈ìuds
    - 330 Tflops 
* 2 noeuds large m√©moire 112 coeurs, 3To RAM
* 2 noeuds GPU de visualisation, 52 coeurs CPU (bi-processeurs 26 coeurs), d√©di√©s et configur√©es pour le post-traitement (Poweredge R740 embarquant du RTX6000)
* 1,3 Po de stockage d√©di√© au calcul
    * 1 Po de stockage rapide sous Lustre
    * 350 To de stockage p√©renne
* R√©seau d‚Äôinterconnexion Intel OmniPath 100 Gb/s
* Pas d‚Äôacc√©l√©rateur
* Gestionnaire de soumission de job : [SLURM (Simple Linux Utility for Resource Management)](https://slurm.schedmd.com/documentation.html)
    * Ordonnancement de t√¢ches dans les files d‚Äôattentes (arbitrage)


<br>
**Fonctionnement :**

  * Les utilisateurs appartenant √† des groupes ex√©cutent des jobs sur des partitions
  * Une partition est un ensemble de n≈ìuds


<br>
**Partitions pour les Ciradiens :**

Il faut choisir la partition sur laquelle lancer vos jobs. Il existe plusieurs partions pour les ciradiens :


| Partition   | Description            | Limite de <br> temps | nb nodes  | nb CPUs <br> par noeud |M√©moire par d√©faut * | M√©moire max |
| :---------  | :------------          | :---------:     |:--------: |:------: | :------: | :------: |
| agap_short  | Pour des jobs rapides  | 1 h             | 71        | 28      | 4 Go     | 128 Go   |
| agap_normal | Partition par d√©faut   | 2 j             | 67        | 28      | 4 Go     | 128 Go   |
| agap_long   | Pour jobs chronophages | Pas de limite   | 67        | 28      | 4 Go     | 128 Go   |
| agap_bigmem | calculs grosse m√©moire | Pas de limite   | 1         | 112     | 28 Go    | 3 To     |




$*$ La m√©moire vive par noeud est limit√©e par d√©faut (voir colonne 6) mais elle peut √™tre augment√©e en ajoutant la ligne :

* `--mem=XG` (pour la m√©moire alou√©e pour le job en enti√©)
* ou `--mem-per-cpu=XG`  (pour la m√©moire alou√©e pour chaque CPU)

dans votre script batch (voir section [Soumission de job](#proc_soumission)) avec "X" la quantit√© de m√©moire. Voir colonne 7 pour la quantit√© de m√©moire max par noeud. 
Ces 2 param√®tres sont exclusifs l'un l'autre. 





















[######################################################################################]: # 
<br><br>

# 2. Connexion au Cluster {#connexion}

---

C'est tr√®s simple ! La connexion au cluster de calcul haute performance se fait via le protocole SSH. Le nom d‚Äôh√¥te de la machine de connexion est `muse-login.meso.umontpellier.fr`.

Suivant votre syst√®me d‚Äôexploitation, vous pouvez vous y connecter comme suit :

**Sous linux ou Mac :**

Ouvrir une connexion ssh dans un terminal en tapant la commande suivante : 

```
ssh ¬´nom_utilisateur¬ª@muse-login.meso.umontpellier.fr
```
Entrer ensuite votre MDP.

Sous Mac, vous pouvez √©galement utiliser le logiciel Xquartz.

Vous voil√† maintenant connect√© au cluster Muse. Le cluster Muse utilise le gestionnaire de job SLURM. C'est d'ici que vous pourez ex√©cuter et g√©rer vos jobs avec les commandes sp√©cifiques SLURM (voir plus bas pour les principales commandes). 



**Sous windows :**

Installer le logiciel MobXterm (https://mobaxterm.mobatek.net/download-home-edition.html). Lors de la premi√®re connexion, il faut la configurer !

Configuration :

1. Cliquer sur le bouton Session (en haut √† gauche)
2. Une fen√™tre "*Session settings*" s'ouvre alors
3. Cliquer sur SSH (en haut √† gauche)
4. Remplir les champs suivant : 
    a. *Remote host* : `muse-login.meso.umontpellier.fr`
    b. S√©lectionner *Specify username*
    c. Entrer votre nom d'utilisateur
    d. *Port* : 22
5. Cliquer sur OK


![](Figures/MobaXterm1-2.png)


6. Un terminal unix s'ouvre. 
7. Il faut ensuite entrer votre mot de passe (rien ne s'affiche lorsque vous tapez le mdp, c'est un r√©glage de s√©curit√©) puis valider en appuyant sur "entr√©e".
8. MobaXterm vous demande si vous voulez enregistrer le mdp pour ne plus vous le demander. C'est vous qui voyez !

![](Figures/MobaXterm2-2.png)


> ü§© Pour les prochaines fois, vous n'aurez qu'√† ouvrir MobaXterm et √† cliquer sur votre session que vous trouverez dans l'onglet "*User sessions*" sur la gauche.  
Vous pouvez √©galement cr√©er un raccourci sur votre bureau en faisant un clique droit dessus. Cela permet d'ouvrir votre session en m√™me temps que le logiciel se lance. C'est trop bien ü§©



Vous voil√† maintenant connect√© au cluster Muse. Le cluster Muse utilise le gestionnaire de job SLURM.  C'est d'ici que vous pourrez ex√©cuter et g√©rer vos jobs avec les commandes sp√©cifiques SLURM (voir section [Soumission de jobs](#soumission)). 








**Quelsques commandes Linux utiles :**

* `ls` pour afficher le contenu du r√©pertoir courant
* `ls -a` pour afficher tous les fichiers (m√™me cach√©) du r√©pertoir courant
* `cd "path"` pour changer de r√©pertoir
* `cd ..` pour aller au r√©pertoir parent
* `pwd` pour afficher le chemin absolut du r√©pertoir courant (depuis la racine)
* ‚¨ÜÔ∏è‚¨áÔ∏è **Fl√®che haut/bas** pour naviger dans historique des commandes utilis√©es

Pour plus d'info sur les commandes Linux de bases :
https://doc.ubuntu-fr.org/tutoriel/console_commandes_de_base





[######################################################################################]: # 
<br><br>

# 3. Transfer de fichiers {#transfer}

---

Pour soumettre vos jobs, il va falloir envoyer vos scripts sur le cluster. Il vous faudra ensuite r√©cup√©rer les fichiers g√©n√©r√©s par vos jobs. Pour ce faire, on va utiliser le logiciel FileZilla. Il est disponible sous Windows, OSX et Linux. Pour le t√©l√©chargement de fichiers volumineux du cluster vers votre machine (long avec FileZilla) il est possible d'utiliser "rsunc" (voir [annexe A](#annexes_rsunc))




**Installer FileZilla :** https://filezilla-project.org/download.php?show_all=1


> **Remarque pour Linux** : Filezilla est disponible par l‚Äôinterm√©diaire de votre Gestionnaire de paquets `apt-get install filezilla`

**Pr√©sentation de FileZilla : **

![](Figures/Filezilla2.png)

Pour ce connecter, remplir dans la zone de connection :

* **H√¥te** : `sftp://muse-login.meso.umontpellier.fr`
* **Nom d'utilisateur** : votre nom d'utilisateur 
* **Mot de passe** : votre mot de passe
* **Port** : 22


> ü§© Apr√®s la premi√®re connexion, ces informations seront enregistr√©es et vous pourrez vous connecter facilement en cliquant sur la petite fl√®che √† c√¥t√© de "Connexion rapide"

Vous pouvez transf√©rer un fichier dans un sens ou dans l'autre en cliquant droit dessus puis cliquer sur "T√©l√©vers√©" ou "T√©l√©charger".










[######################################################################################]: # 
<br><br>

# 4. Les espaces de stockage  {#stockage}

---

Il y a plusieurs espaces de stockage. Les fichiers d√©pos√©s sur le r√©pertoire "scratch" sont temporaires pour effectuer vos calculs, et sont automatiquement supprim√©s √† 60 jours. Les documents destin√©s √† √™tre conserv√©s doivent √™tre d√©pos√©s sur votre r√©pertoire "home".

Email de Bertrand Pitollat du 19/10/2021 :


Vous disposez de plusieurs espaces de stockage sur le cluster Muse :

- **home directory** : C'est votre point d'entr√©e sur le cluster Muse.
  * Il est h√©berg√© sur la baie NFS du cluster Muse.
  * Il n'est ni sauvegard√© ni r√©pliqu√©.
  * Il est limit√© √† un quota de 50 Go (hors autres espaces de stockage).
  * Il est accessible en lecture et en √©criture depuis les noeuds de login et en lecture seule depuis les noeuds de calcul.

- **r√©pertoire personnel sur la baie r√©pliqu√©e : lien replicated**
  * Il est h√©berg√© sur la baie NetApp du cluster Muse.
  * Ce r√©pertoire est personnel.
  * Il est destin√© au stockage long terme des donn√©es personnelles.
  * Il est accessible via le lien replicated de votre home directory (par exemple, /home/pitollatb/replicated => /storage/replicated/cirad_users/pitollatb).
  * Il est sauvegard√© et r√©pliqu√© sur une baie de secours.
  * Il est limit√© √† un quota de 500Go.
  * Il est accessible en lecture et en √©criture depuis les noeuds de login et de calcul.

- **espace projets / unit√©s / √©quipes sur la baie r√©pliqu√©e : lien projects**
  * Cet espace est h√©berg√© sur la baie NetApp du cluster Muse.
  * Il est destin√© au stockage long terme des donn√©es projets / unit√©s / √©quipes.
  * L'espace est accessible via le lien projects de votre home directory (par exemple, /home/pitollatb/projects => /storage/replicated/cirad/projects).
  * Il est sauvegard√© et r√©pliqu√© sur une baie de secours.
  * Il est partitionn√© par r√©pertoire projet, unit√© ou √©quipe avec un quota initial de 5To pour chaque r√©pertoire.
  * Chaque r√©pertoire projet peut √™tre associ√© √† un groupe d'utilisateurs √† d√©finir par le collectif.
  * L'espace est accessible en lecture et en √©criture depuis les noeuds de login et de calcul.

- **espace work : lien work_agap**
  * Il est h√©berg√© sur la baie NFS du cluster Muse.
  * Cet espace de stockage pr√©c√©demment d√©di√© au stockage des donn√©es projets ne doit plus √™tre utilis√©.
  * Les donn√©es s'y trouvant doivent √™tre transf√©r√©es dans le nouvel espace projets / unit√©s / √©quipes.
  * Il n'est ni sauvegard√© ni r√©pliqu√©.
  * Il est accessible via le lien work_agap de votre home directory (par exemple, /home/pitollatb/work_agap => /nfs/work/agap).
  * Il est accessible en lecture et en √©criture depuis les noeuds de login et en lecture seule depuis les noeuds de calcul.

- **espace personnel scratch : lien scratch**
  * Il est h√©berg√© sur la baie Lustre du cluster Muse.
Ce espace est personnel.
  * Il est rapide et performant et doit √™tre utilis√© pour h√©berger les donn√©es temporaires de calcul.
  * A la fin du calcul, les donn√©es doivent √™tre supprim√©es ou d√©plac√©es.
  * Il est accessible via le lien scratch de votre home directory (par exemple, /home/pitollatb/scratch => /lustre/pitollatb).
  * Il n'est ni sauvegard√© ni r√©pliqu√©.
  * Il est limit√© dans le temps : les donn√©es vieilles de plus de 2 mois seront bient√¥t automatiquement supprim√©es.
  * Il est accessible en lecture et en √©criture depuis les noeuds de login et de calcul.

- **banques de donn√©es scratch : /lustre/agap**
  * Cet espace communautaire stocke les banques de donn√©es.
  * Il est h√©berg√© sur la baie Lustre du cluster Muse pour optimiser les calculs.
  * Il n'est ni sauvegard√© ni r√©pliqu√©.
  * Il ne doit pas √™tre utilis√© pour stocker de donn√©es personnelles.
  * Il est accessible √† l'emplacement /lustre/agap.
  * Les banques maintenues par biomaj sont accessibles √† l'emplacement /lustre/agap/BANK/biomaj.

- **espace web :** Par ailleurs, il existe un espace d√©di√© pour h√©berger les donn√©es affich√©es/diffus√©es par nos diff√©rents services web (genome hubs, ...).
Nous contacter si n√©cessaire.

**Important :**
Je vous rappelle que pour des raisons de performance du cluster Muse, toutes les √©critures issues des jobs doivent √™tre redirig√©es vers votre r√©pertoire scratch et qu'il faut bannir toute lecture intensive depuis les espaces NFS et NetApp.






[######################################################################################]: # 
<br><br>

# 5. Procedure de soumission de jobs R  {#proc_soumission}

---

Dans cette section j'explique comment soumettre des jobs en parall√®le sous R. 


Pour illustrer la soumission d'un job en parall√®le, nous utiliserons l'Exemple_R. Dans cet exemple bidon, je r√©p√®te l'op√©ration 2*k pour k=1 √† 50. Je veux parall√©liser ces op√©rations sur 10 coeurs pour aller 10 fois plus vite. Je sauvegarde chaque r√©sultat dans un ".Rdata" dans un fichier "results".


Pour soumettre un job, vous devez choisir entre :

  * Un mode d‚Äôex√©cution en temps r√©el avec la commande srun directement dans le terminal (non d√©taill√© dans ce tuto)
  * Un mode d‚Äôex√©cution diff√©r√© en d√©finissant son job dans un script ***batch*** (.sh) et en le lancer √† l‚Äôaide de la commande `sbatch` dans le terminal


‚ö†Ô∏è **J'explique ici uniquement la proc√©dure diff√©r√©e avec la commande `sbatch`** 

Cette proc√©dure consiste √† d√©finir les param√®tres d'ex√©cution dans un fichier *batch* (.sh)

Ce fichier peut √™tre √©diter avec [**Notepad++**](https://notepad-plus-plus.org/downloads/) ou **Rstudio**.
Pour le cr√©er : 

* avec **Notepad++** : *File > New* puis sauvegarder avec l'extension *.sh*
* avec **Rstudio** : *File > New File > Shell Script*

üëâ Mais le plus simple est de reprendre un script ***batch*** (.sh) qu'on a sous la main d'un autre projet.



üí•üî• **Alerte Windows** üö®üßØ **Attention aux retours √† la ligne !!!**  
Par d√©fault dans Windows les retours chariot sont de type DOS et ils ne sont pas compatible avec Linux ou Max de type UNIX (Posix LF) et √ßa plantle !  
Il faut soit :

* utiliser **Notepad++** en faisant :  
*Edition > Convertir les sauts de ligne > Convertir en format UNIX (LF)*  
‚ö†Ô∏è a faire pour chaque nouveau fichier
* utiliser **Rstudio** en r√©glant l'option des retours √† la ligne de type Unix :  
*Tools > Global options > Code > Saving > Serialization > Line ending conversion > Posix (LF)*  
A faire qu'une seule fois ‚ù§Ô∏èüí™ Il sait tout faire ce Rstudio ! üí™‚ù§Ô∏è 





**Prenons le fichier *batch* de l'Exemple_R_openMP_RF** pour voir sa construction


```
#!/bin/bash
#SBATCH --partition=agap_short  # la partition
#SBATCH --job-name openMP_RF    # nom du job
#SBATCH --nodes=1               # NB noeuds (MPI processes, openMP -> 1)
#SBATCH --ntasks=1              # NB t√¢ches (MPI processes, openMP -> 1)
#SBATCH --ntasks-per-node=1     # NB t√¢ches par noeud (MPI processes, openMP -> 1)
#SBATCH --cpus-per-task=10      # NB CPUs par task
#SBATCH --mem-per-cpu=100M      # M√©moire par CPU
#SBATCH --time=0-00:10:00       # Temps limite (10 min)

module purge
module load cv-standard
module load R/3.6.1

# OpenMP runtime settings
export OMP_NUM_THREADS=$SLURM_CPUS_ON_NODE

cd $SLURM_SUBMIT_DIR   # Pour se mettre dans le r√©pertoir o√π est ex√©cuter le .sh

mkdir ./Rout           # Crer le dossier Rout pour les sorties console de R
mkdir ./results        # cr√©er le dossier "results" pour la sauvegarde de mes r√©sultats
R CMD BATCH ./script_RF.R    ./Rout/script_RF.Rout
```

Ce fichier se d√©compose en 3 parties :

* 1re partie : chaque ligne commen√ßant par `#SBATCH` d√©crit un param√®tre **SLURM** <br>
Pleins d'options existent, se r√©f√©rer √† la documentation du cluster pour plus d'info (https://meso-lr.umontpellier.fr/documentation-utilisateurs/).

* 2√®me partie : Il faut ensuite charger les **modules** (logiciels, compilateurs) avec la commande `module load`. 
[Les modules reposent sur un syst√®me de d√©pendances et de conflits fix√©s par la personne ayant install√© ou compil√© le logiciel ou la librairie vis√©e.]: # 
On commance par d√©charcher tous les modules qui peuvent √™tre charg√©s.
Pour utiliser le logiciel R, en fonction de la version, il faut charger le module `cv-standard` et ensuite `R/version` ou `R` (charge la derni√®re version 4.2.2). Si votre code utilise un autre langage (c++, python, ...), il faudra alors charger les modules en cons√©quence. Pour voir la liste des modules disponibles : `module avail`. Plus d'info sur les modules dans la documentation du cluster (https://meso-lr.umontpellier.fr/documentation-utilisateurs/) section "Environnement logiciel du Cluster Muse" et le TP : https://meso-lr.umontpellier.fr/wp-content/uploads/2020/03/1-TP-Environment_module3.pdf. Je vous conseille de pr√©cicer la version de R avec laquelle vous voulez travailler pour ne pas avoir de surprise si une nouvelle version est install√©e. Les versions de R disponibles sont :
    * en local (install√© par muse@lr) :
        * `R/3.6.1`
        * `R/3.6.1-tcltk `
        * `R/3.6.3 `
        * `R/4.0.2`
        * `R/4.2.2`
    * dans cv-standard (la majorit√© des compilateurs et biblioth√®ques standards) :
        * `R/3.3.1`
        * `R/3.4.3`
    
**Vous pouvez aussi installer vos propres logiciels.**

* 3√®me partie : Enfin la ligne pour ex√©cuter le script R : `R CMD BATCH ` suivie du chemin d'acc√®s vers le script, suivi du chemin d'acc√®s vers le **Rout** pour √©crire les sorties (ce qui s'affiche dans la console de Rstudio en temps normal). **Pensez √† cr√©er le fichier Rout dans votre projet**.




Pour lancer votre code, il faut ex√©cuter dans le terminal (apr√®s s'√™tre plac√© dans le bon r√©pertoire) le fichier batch associ√© avec la commande :
```
sbatch job_submission.sh
```




**Attention** : si votre code n√©cessite le chargement de packages, il faut imp√©rativement les installer avant. Pour ce faire, dans le terminal, charger les modules puis lancer R :
```
module load cv-standard R/3.6.1
R
```
Installer ensuite les packages (il vous faudra choisir un miroir) :
```
install.packages("doParallel")
```
Enfin quitter R avec la commande `q()`.



















[######################################################################################]: # 
<br><br>

# 6. Les commandes SLURM utiles {#commandes}

---

Pour voir l'√©tat de tous les jobs (de tous les utilisateurs)
```
squeue
```


Pour voir l'√©tat de vos jobs 
```
squeue -u $USER -o '%.18i %.9P %.20j %u %.8T %.10M %.9l %.6D %R'
```


Pour tuer un job
```
scancel <JOB_ID>
```


Pour voir le nombre de CPUs disponibles par noeud (tr√®s utile pour choisir le nombre de coeurs pour passer devant toute la fille d'attente)
```
sinfo -o "%P %n %C"
```

* La 1er colonne (%P) donne la partition
* La 2√®me colonne (%n) donne l'identifiant du noeud
* La 3√®me colonne (%C) donne le nombre de CPUs par √©tat dans le format "allou√©/libre/autre/total"

![](Figures/sinfo.png)



Consulter la quantit√© de m√©moire consomm√©e par le job apr√®s son ex√©cution : 
```
sacct -o JobID,Node,AveRSS,MaxRSS,MaxRSSTask,MaxRSSNode,TRESUsageInTot%250 -j <JOB_ID> 
```



Plus d'info sur les commandes ici : https://slurm.schedmd.com/man_index.html
















[######################################################################################]: # 
<br><br>

# 7. Rstudio sur le cluster {#rstudio}

---

http://193.52.26.138/rstudio/auth-sign-in

Rstudio est isol√© sur un noeud d√©di√© (96 CPUs et 3To de m√©moire) et est partag√© avec tous les utilisateurs Rstudio.


**Il est destin√© √† la mise au point des scripts mais il faut √©viter de lancer des calculs lourds directement dessus.
Une fois mis au point il vaut mieux les soumettre via script batch.**









[######################################################################################]: # 
<br><br>

# 8. Ressources {#ressources}

---

**Mailing list d'entraides :**
meso-help@umontpellier.fr


**Site web sur cluster MUSE MESO@LR :**
https://meso-lr.umontpellier.fr/documentation-utilisateurs/


**Pr√©sentation du cluster MUSE MESO@LR :**
https://meso-lr.umontpellier.fr/wp-content/uploads/2019/11/1-Presentation_cluster_Muse.pdf

**TP-Environment Module :**
https://meso-lr.umontpellier.fr/wp-content/uploads/2020/03/1-TP-Environment_module3.pdf

**TP-SLURM :**
https://meso-lr.umontpellier.fr/wp-content/uploads/2020/04/1-TP-SLURM3.pdf


**Commandes Linux de bases :**
https://doc.ubuntu-fr.org/tutoriel/console_commandes_de_base

**Quick Intro to Parallel Computing in R (et les ref dedans) : **
https://nceas.github.io/oss-lessons/parallel-computing-in-r/parallel-computing-in-r.html










[######################################################################################]: # 

<br><br>

# Annexes {#annexes}

---

## A. Les exemples {#annexes_exemples}

[-----------------------------------------------------------]: # 

### A.1. Exemple R OpenMP sur calibration d'une RF {#ex_R_openMP}

> ‚ö†Ô∏è ATTENTION Pour cet exemple, il faut installer les packages "doParallel", "caret" et "randomForest" dans votre R/3.6.1.


Dans cette exemple, je souhaite calibrer un mod√®le de for√™ts al√©atoires (random forest) sur les donn√©es "iris" (de base dans R).

**Description des donn√©es (`?iris`)** : This famous (Fisher's or Anderson's) iris data set gives the measurements in centimeters of the variables sepal length and width and petal length and width, respectively, for 50 flowers from each of 3 species of iris. The species are Iris setosa, versicolor, and virginica.

> J'ai cumul√© 3 fois le jeu de donn√©es pour arriver √† 450 observations sinon c'est trop rapide.


L'objectif ici est de retrouver la vari√©t√© en fonction des measures faites sur les s√©pales et p√©tales. On est donc dans une classification et on va r√©aliser √ßa avec un Random Forest.

Pour ce faire il faut calibrer le param√®tre "mtry" (Number of variables randomly sampled as candidates at each split). On r√©alise alors une CV √† l'aide du package `caret` et sa fonction `train`. Ce processus implique de lancer plusieurs for√™ts al√©atoires avec des param√®tres diff√©rents. Cela se parall√©lise tr√®s bien (10 RF en parall√®le sur 10 coeurs dans l'exemple (1 par coeur)). Le package `caret` g√®re la paral√©lisation √† votre place avec l'option `allowParallel = TRUE` dans la fonction `trainControl` (mode OpenMP). Il faut juste d√©clarer un nombre de CPUs disponible pour la parall√©lisation en d√©but du script R. Cela peut se faire √† l'aide du package `doParallel` :

```
doParallel::registerDoParallel(cores=10)
```

le script R ressemble √† :
```
library(doParallel, caret, randomForest)

# Parallel settings -------------------------------------------------------
doParallel::registerDoParallel(cores=10)

# the DATA ----------------------------------------------------------------
iris2 <- rbind(iris, iris, iris)

# Split data in train/test set --------------------------------------------
trainingIndex <- createDataPartition(iris2$Species, p=0.8, list=FALSE)
data_train <- iris2[trainingIndex, ]
data_test <- iris2[-trainingIndex, ]

# RF calibration ----------------------------------------------------------
RF_model_train <- train(Species~., data = data_train,
  method = "rf",
  trControl = trainControl(method = "LOOCV", allowParallel = TRUE),
) 

# RF fit ------------------------------------------------------------------
RFFGrid <- expand.grid(mtry=RF_model_train$bestTune$mtry) 
fit_RF <- train(Species~.,data = data_train,
                method = "rf",
                trControl = trainControl(method = "none"),
                tuneGrid = RFFGrid
)

save(fit_RF, file="results/fit_RF_iris.Rdata")


# RF Predictive performances -----------------------------------------------
table(data_test$Species, predict(fit_RF, new=data_test))

```

> Ce script R peut tr√®s bien s'√©x√©cuter sur votre PC (attention √† adapter le nombre de CPU). Pour d√©tecter le nombre de CPU sur votre PC, vous pouvez utiliser la fonction `parallel::detectCores()`. Ne pas prendre plus que le max-1 sur vos PC !



<br>
**Astuce :**
On peut r√©cup√©rer dans R le nombre de CPUs qu'on a d√©clar√© dans le batch (.sh) (variable d'environnement `SLURM_JOB_CPUS_PER_NODE`) avec la commande R :
```
nb_CPUs <- as.integer(Sys.getenv("SLURM_JOB_CPUS_PER_NODE")) 
doParallel::registerDoParallel(cores=nb_CPUs)
```
Cela √©vite les erreurs ;)










[-----------------------------------------------------------]: # 
<br>

### A.2. Exemple R openMP for loop {#ex_R_forloop}




Imaginon que j'ai besoin d'ex√©cuter une fonction ou un code sur diff√©rents param√®tres d'entr√©e ou donn√©es (ou les deux). Je peux alors faire √ßa avec une boucle "for".

Par exemple, je veux appliquer la fonction `my_fct = n * p * k` sur diff√©rents param√®tres d'entr√©e :

* `n` = 1 ou 2
* `p` = 1, 2 ou 3
* `k` = 1 ou 2

Cel√† fait `2*3*2 = 12` combinaisons et donc 12 ex√©cutions de ma fonction. 
Je peux tr√®s bien faire cela avec le code R :

```
# D√©finition de ma fonction
my_fct <- function(n, p, k) return(n*p*k)

# D√©finition d'une grille de param√®tres que je veux faire varier
pars <-  expand.grid(n = 1:2, p = 1:3, k = 1:10)

# ex√©cution de ma fonction sur les diff√©rentes combinaisons de param√®tres
for(i in 1:nrow(pars)){
  result <- my_fct(n=pars$n[i], p=pars$p[i], k=pars$k[i])
  save(result, file = paste0("results/my_result_n=", pars$n[i], "p=", pars$p[i], "k=", pars$k[i], ".Rdata") )
}
```

Cel√† peut-√™tre tr√®s long en fonction de l'application, or **une boucle "for" se parall√©lise tr√®s bien en openMP**.

> Chaque t√¢che (it√©ration de la boucle) a besoin d'acc√©der √† ce qui a √©t√© charg√© dans l'environnement avant la boucle, on a besoin d'√™tre en m√©moire partag√©e $\rightarrow$ **openMP**).

Cela se fait facilement avec la fonction `foreach` du package du m√™me nom. Il faut toutefois d√©clarer un certain nombre de CPU disponible avec la fonction `registerDoParallel` du package `doParallel`. 

**Le script R devient :**

```
library(doParallel)

# Set the number of cores
doParallel::registerDoParallel(cores = 10)

# D√©finition de ma fonction
my_fct <- function(n, p, k) return(n*p*k)

# D√©finition d'une grille de param√®tres que je veux faire varier
pars <-  expand.grid(n = 1:2, p = 1:3, k = 1:10)

# Parallel for loop
foreach::foreach(i = 1:nrow(pars), .verbose = FALSE) %dopar% {
  result <- my_fct(n=pars$n[i], p=pars$p[i], k=pars$k[i])
  save(result, file = paste0("results/my_result_n=", pars$n[i], "p=", pars$p[i], "k=", pars$k[i], ".Rdata") )

  return() # I return nothing because I save each result in ".Rdata" object in folder "results"
}
```

> Ce script R peut tr√®s bien s'√©x√©cuter sur votre PC (attention √† adapter le nombre de CPU). Pour d√©tecter le nombre de CPU sur votre PC, vous pouvez utiliser la fonction `parallel::detectCores()`. Ne pas prendre plus que le max-1 sur vos PC !



**Le fichier batch pour la soummision du job :**
```
#!/bin/bash
#SBATCH --partition=agap_short  # la partition
#SBATCH --job-name ex1          # nom du job
#SBATCH --nodes=1               # NB noeuds (MPI processes, openMP -> 1)
#SBATCH --ntasks=1              # NB t√¢ches (MPI processes, openMP -> 1)
#SBATCH --ntasks-per-node=1     # NB t√¢ches par noeud (MPI processes, openMP -> 1)
#SBATCH --cpus-per-task=10      # NB CPUs par task
#SBATCH --mem-per-cpu=100M      # M√©moire par CPU
#SBATCH --time=00:10:00         # Temps limite
#
#SBATCH --mail-type=begin       # send email when job begins
#SBATCH --mail-type=end         # send email when job ends
#SBATCH --mail-user=benjamin.heuclin@cirad.fr

module purge
module load cv-standard
module load R/3.6.1

# OpenMP runtime settings
export OMP_NUM_THREADS=$SLURM_CPUS_ON_NODE

cd $SLURM_SUBMIT_DIR

mkdir ./Rout 
mkdir ./results
R CMD BATCH ./main_script.R    ./Rout/main_script.Rout

# Rscript ./main_script.R 
```






[-----------------------------------------------------------]: # 
<br>

### A.3. Exemple R array {#ex_R_array}

Le type de soummision "array" est adapt√© pour ex√©cuter un code (une fonction) plusieurs fois avec des param√®tres diff√©rents en entr√©e ou sur des donn√©es diff√©rentes (ou les deux).

Reprenons l'[exemple R de la boucle for](#ex_R_forloop) juste au dessus. 
Dans cet exemple, je souhaite ex√©cuter la fonction `my_fct=n*p*k` sur diff√©rents param√®tres d'entr√©e :

* `n` = 1 ou 2
* `p` = 1, 2 ou 3
* `k` = 1 ou 2

**Les 12 ex√©cutions sont ind√©pendantes** et donc on peut optimiser le lancement de ce job √† l'aide d'un **array**. Le principe est qu'on demande au cluster un certain nombre de CPUs et le cluster va les choisir potentiellement dans des noeuds (node) differents.   
On est donc sur une forme de paral√©lisation hybride OpenMPI ! 

> Lorsqu'il y a beaucoup de jobs en attente sur le cluster, cela permet √† votre job de passe plus vite car c'est plus facile de prendre *n* CPUs par-ci par-l√† plut√¥t que *n* CPUs sur le m√™me noeud. La r√©servation de ressources est optimis√©e !

Pour ce faire, on sp√©cifie l'option `--array` dans le batch (.sh) :


```
#!/bin/bash
#SBATCH --partition=agap_short  # la partition
#SBATCH --job-name array        # nom du job
#SBATCH --array=1-12            # OPTION ARRAY 
#SBATCH -o array-%a.out
#SBATCH --mem-per-cpu=100M      # M√©moire par CPU
#SBATCH --time=00:30:00         # Temps limite

module purge
module load cv-standard
module load R/3.6.1

cd $SLURM_SUBMIT_DIR

mkdir ./results
Rscript ./main_script.R $SLURM_ARRAY_TASK_ID
```

‚ö†Ô∏è **Attention** : On ne pr√©cise pas le nombre de noeud ni de coeur ni de tasks que l'on souhaite. C'est SLURM qui va r√©partir en fonction des ressources disponibles.

Sur la derni√®re ligne d'ex√©cution du script R, on rajoute la variable d'environnement `$SLURM_ARRAY_TASK_ID`, cela permet au script R de r√©cup√©rer le num√©ro de la t√¢che.  
Et enfin dans le script R il faut utiliser la commande `as.numeric(commandArgs(trailingOnly=TRUE)[1])` pour r√©cup√©rer l'indice (*i*). Je peux ainsi lancer la fonction sur la ligne *i* √®me ligne de ma grille de param√®tres.

```
# on r√©cup√®re l'indice de la t√¢che ($SLURM_ARRAY_TASK_ID)
i = as.numeric(commandArgs(trailingOnly=TRUE)[1])

# D√©finition d'une grille de param√®tres que je veux faire varier
pars <-  expand.grid(n = 1:2, p = 1:3, k = 1:2)

# D√©finition de ma fonction
my_fct <- function(n, p, k) return(n*p*k)

# Execution de la fonction sur la ligne i de la grille de param√®tres
result <- my_fct(n=pars$n[i], p=pars$p[i], k=pars$k[i])
print(paste0("Le resultat de ma fonction est : ", result))
```

> La scructuration du code R est totalement repens√©, pas besoin de d√©clarer un nombre de CPUs comme dans l'exemple pr√©c√©dent. Ici le script est pens√© pour une √©x√©cution et il doit √™tre ind√©pendant des autres ex√©cutions (on charge tout ce dont la t√¢che √† besoin : la grille de param√®tres, la fonction). Ce script ne peut pas s'√©x√©cuter sur votre PC tel quel  contrairement au script R pr√©c√©dent !


<br>
Pour supprimer des t√¢ches dans un job array :

```
# Cancel array ID 1 to 3 from job array 20
$ scancel 20_[1-3]

# Cancel array ID 4 and 5 from job array 20
$ scancel 20_4 20_5

# Cancel all elements from job array 20
$ scancel 20
```
Plus d'info ici : https://slurm.schedmd.com/job_array.html







## B. Script batch corrompu √† cause des retours √† la ligne WINDOWS {#annexes_unix_LF}

**Si tu as un fichier corrompu √† cause des retours √† la ligne au format WINDOWS**
```
-bash-4.2$ sbatch job_submission.sh
sbatch: error: Batch script contains DOS line breaks (\r\n)
sbatch: error: instead of expected UNIX line breaks (\n).
```
Tu peux soit :

* dans **Notepad++** faire :  *Edition > Convertir les sauts de ligne > Convertir en format UNIX (LF)* et sauvegarder
* dans **Rstudio** (avec l'option qui va bien pour les fin de lignes "unix LF" comme d√©crit au dessus) : modifier l√©g√®rement ton .sh (avec un saut de ligne par exemple) et le sauvegarder. Rstudio va automatiquement convertir les sauts de ligne










## C. rsync EN CONSTRUCTION {#annexes_rsunc}

source : https://meso-lr.umontpellier.fr/documentation-utilisateurs/

```
#! /usr/bin/env bash
###################################################################
# rsync.sh : Ecrit par J√©r√©my Verrier				  #
# Script permettant la copie s√©curis√©e de fichiers ou de dossiers #
###################################################################

# Entrez votre nom d'utilisateur
USER=
# Entrez le chemin complet du r√©pertoire ou du fichier √† copier (/home/verrier/work/results.txt)
DOSSIER_CLUSTER=
# Entrez le chemin complet du r√©pertoire ou du fichier de destination
DOSSIER_PERSO=

while [ 1 ]
do
    rsync -avz --progress --partial "${USER}"@muse-login.meso.umontpellier.fr:"${DOSSIER_CLUSTER}" "${DOSSIER_PERSO}"
    if [ "$?" = "0" ] ; then
        echo "Rsync OK"
        exit
    else
        echo "Rsync erreur, nouvelle tentative dans 1 minute..."
        sleep 60
    fi
done
```


A enregister au au format .sh ou √† t√©l√©charger avec le lien ci-dessous.

[Ce script](https://hpc-lr.umontpellier.fr/wp-content/uploads/2017/05/rsync.txt) vous permet de copier des donn√©es depuis le cluster Muse vers votre machine.
Il vous faut modifier les champs USER, DOSSIER_CLUSTER et DOSSIER_PERSO et ensuite le lancer avec la commande ¬´ bash rsync ¬ª.
Il est vivement conseill√© d‚Äôutiliser ce script lors de t√©l√©chargement de fichiers volumineux.

















